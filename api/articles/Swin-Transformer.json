{"title":"Swin-Transformer","uid":"ec562ad6a6c391a3dd5ebfc55c638744","slug":"Swin-Transformer","date":"2022-03-21T13:27:37.000Z","updated":"2022-03-21T13:58:11.754Z","comments":true,"path":"api/articles/Swin-Transformer.json","keywords":null,"cover":[],"content":"<p>原文链接： <a href=\"https://arxiv.org/pdf/2103.14030.pdf\">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</a></p>\r\n<h1 id=\"引言\">引言</h1>\r\n<p>作者认为将语言领域的高性能转移到视觉领域的重大挑战可以用两种模式的差异来解释。</p>\r\n<ul>\r\n<li>规模：与语言Transformer中作为基本处理元素的单词符号不同，视觉元素在规模上有很大的变化，例如目标检测，不同的目标规模差别是很大的，在ViT中，token的大小是固定的，每一层处理的都是patch size大小的区域，虽然通过注意力来得到一个全局的理解，但是对多尺度特征的理解相对较弱</li>\r\n<li>分辨率：图像分辨率比段落中文字要高很多，一些视觉任务如语义分割需要在像素级进行密集预测，而Transformer在高分辨率图像上是难以处理的，它的计算复杂度是图像尺寸的平方</li>\r\n</ul>\r\n<img src=\"/post/Swin-Transformer/image1.png\" class=\"\" title=\"[]\">\r\n<ul>\r\n<li>Swin Transformer通过合并patch来构建分层特征映射，只在局部窗口内计算自注意力，因此对于图像大小具有线性复杂度，而ViT中，对于图像大小计算复杂度为二次</li>\r\n</ul>\r\n<img src=\"/post/Swin-Transformer/image2.png\" class=\"\" title=\"[]\">\r\n<ul>\r\n<li>在连续的自注意力层之间移动窗口，在第l层，窗口为规则划分，在第l+1层，窗口向右下移动，得到的新的窗口跨越了上一层中的不同窗口，从而将不同的区域联系在一起</li>\r\n</ul>\r\n<h1 id=\"方法\">方法</h1>\r\n<h2 id=\"总体架构\">总体架构</h2>\r\n<img src=\"/post/Swin-Transformer/image3.png\" class=\"\" title=\"[]\">\r\n<ul>\r\n<li>输入H×W×3的图片，首先分为4×4大小的patch，得到H/4×W/4个48维向量，对这些向量进行线性映射得到Transformer层的输入，H/4×W/4个token，每个token纬度为C</li>\r\n<li>Swin Transformer Block输入输出尺寸一致，内部自注意力的计算是基于窗口的</li>\r\n<li>Patch Merging层将4个patch合并为1个，降低token个数，将4个patch合并为1个导致向量纬度变为4C，然后在C的纬度上通过1×1的卷积将纬度变为2C。相当于对输入的张量，宽和高减半，通道数变为原来的2倍</li>\r\n<li>W-MSA和SW-MSA分别是具有规则窗口和移动窗口的多头自注意力，窗口大小为M×M</li>\r\n</ul>\r\n<h2 id=\"基于移动窗口的自注意力\">基于移动窗口的自注意力</h2>\r\n<p>W-MSA基于规则窗口的多头自注意力，有效减少了计算复杂度，但是由于注意力是在窗口内部计算的，无法得到窗口之间的关注度，因此每个W-MSA的Transformer后都跟一个SW-MSA的Transformer，基于移动窗口的自注意力，向右下方移动窗口后，新的窗口包含了之前不同窗口内的信息，这样在窗口内计算自注意力就能得到窗口间的关注度。但是移动窗口后，有的窗口不能保证是固定的大小，窗口数目增多了，不利于在一个batch中计算，即使使用padding，计算复杂度也提高了。</p>\r\n<img src=\"/post/Swin-Transformer/image4.png\" class=\"\" title=\"[]\">\r\n<ul>\r\n<li>作者提出了一种高效的方法来解决移动窗口后产生的问题，首先将不完整的窗口循环移位拼接在右下方，补全不完整的窗口，最终得到的窗口数目与规则窗口数目保持一致。循环移位后本不该产生注意力的块由于拼接在一个窗口，运算可能会产生注意力，为了消除这种影响，作者定义了一些掩码，让拼接出的窗口中不同的部分各自计算自注意力。最后，需要将拼接还原，恢复原有的语义信息</li>\r\n</ul>\r\n<img src=\"/post/Swin-Transformer/image5.png\" class=\"\" title=\"[]\">\r\n<ul>\r\n<li>每个patch是一个向量，自注意力计算时，需要计算<span class=\"math inline\"><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.233ex\" height=\"2.343ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -841.7 2312.8 1035.7\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D444\" d=\"M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(791,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(974,363) scale(0.707)\"><path data-c=\"1D447\" d=\"M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z\"></path></g></g></g></g></svg></mjx-container></span>，假设窗口大小为7×7，则一个窗口内有49个patch，<span class=\"math inline\"><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.79ex\" height=\"2.032ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -704 791 898\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D444\" d=\"M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z\"></path></g></g></g></svg></mjx-container></span>的大小为49×C，自注意力中<span class=\"math inline\"><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.443ex\" height=\"1.904ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -841.7 1521.8 841.7\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D43E\" d=\"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(974,363) scale(0.707)\"><path data-c=\"1D447\" d=\"M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z\"></path></g></g></g></g></svg></mjx-container></span>就是<span class=\"math inline\"><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.104ex\" height=\"2.343ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -841.7 1371.8 1035.7\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D444\" d=\"M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(824,363) scale(0.707)\"><path data-c=\"1D447\" d=\"M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z\"></path></g></g></g></g></svg></mjx-container></span>。若第i行向量<span class=\"math inline\"><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex\" xmlns=\"http://www.w3.org/2000/svg\" width=\"6.244ex\" height=\"1.927ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -694 2760 851.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(361,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(846,0)\"><path data-c=\"1D458\" d=\"M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1367,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1833,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(633,-150) scale(0.707)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container></span>不需要与第j行向量<span class=\"math inline\"><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.666ex\" xmlns=\"http://www.w3.org/2000/svg\" width=\"6.351ex\" height=\"2.236ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -694 2807.3 988.2\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(361,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(846,0)\"><path data-c=\"1D458\" d=\"M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1367,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1833,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(633,-150) scale(0.707)\"><path data-c=\"1D457\" d=\"M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z\"></path></g></g></g></g></svg></mjx-container></span>计算注意力，那么只需在注意力计算后的结果矩阵中的第i行第j列位置和第j行第i列位置加上一个很大的负值（例如-100）即可，这个负值经softmax可得到接近于0的结果。</li>\r\n</ul>\r\n<h2 id=\"模型变体\">模型变体</h2>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>Swin-T</th>\r\n<th>C=96</th>\r\n<th>layer numbers = {2, 2, 6, 2}</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td>Swin-S</td>\r\n<td>C=96</td>\r\n<td>layer numbers = {2, 2, 18, 2}</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>Swin-B</td>\r\n<td>C=128</td>\r\n<td>layer numbers = {2, 2, 18, 2}</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>Swin-L</td>\r\n<td>C=192</td>\r\n<td>layer numbers = {2, 2, 18, 2}</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h1 id=\"实验\">实验</h1>\r\n<h2 id=\"分类任务\">分类任务</h2>\r\n<img src=\"/post/Swin-Transformer/image6.png\" class=\"\" title=\"[]\">\r\n<ul>\r\n<li>ImageNet-1K包含1.28M张训练图片和50K张测试图片，来自1000个类别，（a）是直接在ImageNet-1K上训练得到的结果，在较小的数据集上，ViT表现稍差，Swin Transformer与EffNet-B7不分伯仲，EffNet-B7优势在于输入图片尺寸更大，参数量较小</li>\r\n<li>ImageNet-1K包含14.2M张图片和22K类，ViT和Swin Transformer经大训练集预训练后优势显著，有着更高的准确率和更少的参数</li>\r\n</ul>\r\n<h2 id=\"目标检测任务\">目标检测任务</h2>\r\n<img src=\"/post/Swin-Transformer/image7.png\" class=\"\" title=\"[]\">\r\n<ul>\r\n<li>（a）：骨干网络ResNet-20与Swin-T在不同方法上比较，Swin-T更优</li>\r\n<li>（b）：不同的骨干网络，在3类参数规模下的效果对比，Swit-T更优</li>\r\n<li>（c）：任意网络任意方法任意规模，最优结果是Swin-L产生的</li>\r\n</ul>\r\n<h2 id=\"语义分割任务\">语义分割任务</h2>\r\n<img src=\"/post/Swin-Transformer/image8.png\" class=\"\" title=\"[]\">\r\n<ul>\r\n<li>在计算成本相似的条件下，Swin仍是最好的，使用Swin-L在ImageNet-22K预训练后，mIoU比之前最佳模型SETR高了3.2，而SETR参数量比Swin-L高</li>\r\n</ul>\r\n","feature":true,"text":"原文链接： Swin Transformer: Hierarchical Vision Transformer using Shifted Windows 引言 作者认为将语言领域的高性能转移到视觉领域的重大挑战可以用两种模式的差异来解释。 规模：与语言Transformer中作...","link":"","photos":[],"count_time":{"symbolsCount":"2.2k","symbolsTime":"2 mins."},"categories":[{"name":"论文","slug":"论文","count":4,"path":"api/categories/论文.json"}],"tags":[{"name":"Transformer","slug":"Transformer","count":4,"path":"api/tags/Transformer.json"},{"name":"cv","slug":"cv","count":3,"path":"api/tags/cv.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%BC%95%E8%A8%80\"><span class=\"toc-text\">引言</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">方法</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%80%BB%E4%BD%93%E6%9E%B6%E6%9E%84\"><span class=\"toc-text\">总体架构</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%9F%BA%E4%BA%8E%E7%A7%BB%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B\"><span class=\"toc-text\">基于移动窗口的自注意力</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E5%8F%98%E4%BD%93\"><span class=\"toc-text\">模型变体</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%AE%9E%E9%AA%8C\"><span class=\"toc-text\">实验</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1\"><span class=\"toc-text\">分类任务</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%BB%BB%E5%8A%A1\"><span class=\"toc-text\">目标检测任务</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1\"><span class=\"toc-text\">语义分割任务</span></a></li></ol></li></ol>","author":{"name":"JPFLY","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"Be Better!!","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"DETR","uid":"cb267603e909abe660af40ea689ab423","slug":"DETR","date":"2022-03-21T13:29:46.000Z","updated":"2022-03-21T13:57:29.614Z","comments":true,"path":"api/articles/DETR.json","keywords":null,"cover":[],"text":"原文链接：End-to-End Object Detection with Transformers 引言 目标检测的目标是为每个感兴趣的对象预测一组边界框和类别标签。当前大多数目标检测方法通过回归和分类来获得最终的检测结果，性能受到以下因素的显著影响：消除重复的预测后处理，锚点...","link":"","photos":[],"count_time":{"symbolsCount":"1.5k","symbolsTime":"1 mins."},"categories":[{"name":"论文","slug":"论文","count":4,"path":"api/categories/论文.json"}],"tags":[{"name":"Transformer","slug":"Transformer","count":4,"path":"api/tags/Transformer.json"},{"name":"cv","slug":"cv","count":3,"path":"api/tags/cv.json"}],"author":{"name":"JPFLY","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"Be Better!!","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"Vision-Transformer","uid":"93157edbbe6cf715014badf14ef4775c","slug":"Vision-Transformer","date":"2022-03-21T13:12:21.000Z","updated":"2022-03-21T14:05:49.028Z","comments":true,"path":"api/articles/Vision-Transformer.json","keywords":null,"cover":[],"text":"原文链接：AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE 引言 基于自注意力的架构Transformer已成为NLP领域的首选模型，它的主要方法是在大型文本语料库上进行预训练，然...","link":"","photos":[],"count_time":{"symbolsCount":"2.5k","symbolsTime":"2 mins."},"categories":[{"name":"论文","slug":"论文","count":4,"path":"api/categories/论文.json"}],"tags":[{"name":"Transformer","slug":"Transformer","count":4,"path":"api/tags/Transformer.json"},{"name":"cv","slug":"cv","count":3,"path":"api/tags/cv.json"}],"author":{"name":"JPFLY","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"Be Better!!","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}