{"name":"JPFLY","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"Be Better!!","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}},"post_list":[{"title":"Attention-Is-All-You-Need","uid":"7bb7fc64b6abbcc4ecc3eadbe6fac18b","slug":"Attention-Is-All-You-Need","date":"2022-03-21T12:37:39.000Z","updated":"2022-03-21T13:01:28.956Z","comments":true,"path":"api/articles/Attention-Is-All-You-Need.json","keywords":null,"cover":[],"text":"原文链接：Attention Is All You Need Transformer模型结构 Transformer模型遵循encoder-decoder架构，为编码器和解码器使用堆叠的自注意层和逐点全连接的层。 ","link":"","photos":[],"count_time":{"symbolsCount":"1.7k","symbolsTime":"2 mins."},"categories":[{"name":"论文","slug":"论文","count":1,"path":"api/categories/论文.json"}],"tags":[{"name":"Transformer","slug":"Transformer","count":1,"path":"api/tags/Transformer.json"}],"author":{"name":"JPFLY","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"Be Better!!","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}],"categories":1,"tags":1,"word_count":"1.7k","post_count":1}